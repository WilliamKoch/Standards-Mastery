{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Packages to run Pandas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import glob\n",
    "import configparser\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Import Related Function\n",
    "\n",
    "##Import Config File to determine where to put into Google Sheets\n",
    "def ImportTeacherConfig():\n",
    "    #print(os.getcwd())\n",
    "    #os.chdir(r\"C:\\Users\\Altair\\Dropbox\\1819 NSA Mastery Tracking\\Math\\Coapman\\AP Calculus BC\")\n",
    "\n",
    "    Config = configparser.ConfigParser()\n",
    "    Config.read(\"teacher.ini\")\n",
    "    def ConfigSectionMap(section):\n",
    "        dict1 = {}\n",
    "        options = Config.options(section)\n",
    "        for option in options:\n",
    "            try:\n",
    "                dict1[option] = Config.get(section, option)\n",
    "                if dict1[option] == -1:\n",
    "                    DebugPrint(\"skip: %s\" % option)\n",
    "            except:\n",
    "                print(\"exception on %s!\" % option)\n",
    "                dict1[option] = None\n",
    "        return dict1\n",
    "\n",
    "    wks = ConfigSectionMap(\"teacherconfig\")['worksheet']\n",
    "    spreadsheet = ConfigSectionMap(\"teacherconfig\")['spreadsheet']\n",
    "\n",
    "    #print(spreadsheet)\n",
    "    return (wks, spreadsheet)\n",
    "#######\n",
    "###### Import Student Roster ######\n",
    "def ImportRoster():\n",
    "    path = r'.\\Roster'\n",
    "    filename = glob.glob(path + \"/*.xls*\")\n",
    "\n",
    "    Roster = pd.read_excel(filename[0])\n",
    "\n",
    "    Roster.index = Roster.loc[:,'Local Student Id']\n",
    "    Roster = Roster.sort_index()\n",
    "    Roster = Roster[['Local Student Id', 'Student Last Name', 'Student First Name', 'Section', 'Accommodation Level']]\n",
    "    #StandardsList_processed = StandardsList_processed [['Unit', 'Last Date Assessed', 'Priority', 'Standard Code']]\n",
    "    Roster.dropna(inplace=True)\n",
    "    Roster = Roster.drop(['Local Student Id'],axis = 1)\n",
    "    return Roster\n",
    "####\n",
    "\n",
    "####### This is where most importing is taking place #######\n",
    "\n",
    "def GetDatesAssessed():\n",
    "    DatesAssessed = []\n",
    "    path = r'.\\TestInfo'\n",
    "    #This uses a wildcard to get both .xls and .xlsx\n",
    "    filename = glob.glob(path + \"/*.xls*\")\n",
    "    for test in range(len(filename)):\n",
    "        DatesAssessed.append(filename[test][len(path)+1:len(path)+9])\n",
    "\n",
    "    #Processing the dates into better format\n",
    "    DatesAssessed = [e[0:4] + \"-\" + e[4:6] + \"-\" + e[6:8] for e in DatesAssessed]\n",
    "    return DatesAssessed\n",
    "\n",
    "## Read Filenames for Test Info Pages and Response Matrices\n",
    "# Use this later when working with multiple tests at once\n",
    "\n",
    "def GetTestInfoPaths():\n",
    "    path1 = r'.\\TestInfo'\n",
    "    TestInfoNames = glob.glob(path1 + \"/*.xls*\")\n",
    "    return(TestInfoNames) \n",
    "\n",
    "def GetResponsesPaths():\n",
    "    path2 = r'.\\Responses'\n",
    "    ResponsesNames = glob.glob(path2 + \"/*.xls*\")\n",
    "    return (ResponsesNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to clean test info page to included secondary standards in analysis\n",
    "\n",
    "def cleanTestInfo2(TestInfoFileName):\n",
    "    TestInfoAll = pd.DataFrame()\n",
    "    TestInfo = pd.read_excel(TestInfoFileName, sheet_name='Test Information', skiprows=8)\n",
    "    TestInfo.index = range(1, len(TestInfo.index)+1)\n",
    "    Standards1 = TestInfo.loc[:,'(Primary) Standard']\n",
    "    Standards2 = TestInfo.loc[:,'(Secondary) OPTIONAL: Additional Standard']\n",
    "    Type = TestInfo.loc[:,'MC, OER (Question Group)']\n",
    "    Points = TestInfo.loc[:,'Possible Points\\nmust be a whole number (>= 1) if OER']\n",
    "    Correct = TestInfo.loc[:,'Correct Answer']\n",
    "\n",
    "    TestInfo1 = pd.concat([Standards1, Type, Points, Correct], axis = 1)\n",
    "    Qseries = TestInfo1.loc[:,'(Primary) Standard']\n",
    "    LastQuestion = Qseries.last_valid_index()\n",
    "    TestInfo1 = TestInfo1.loc[1:LastQuestion,:]\n",
    "\n",
    "    Bseries = pd.Series(TestInfo.index, dtype = str)\n",
    "    for q in Bseries.index:\n",
    "        Bseries[q] = 'B' + str(Bseries[q])\n",
    "    \n",
    "    TestInfo2 = pd.concat([Standards2, Type, Points, Correct], axis = 1)\n",
    "    TestInfo2.index = Bseries\n",
    "    Qseries = TestInfo2.loc[:,'(Secondary) OPTIONAL: Additional Standard']\n",
    "    LastQuestion = Qseries.last_valid_index()\n",
    "    #LastQuestion = 'B' + LastQuestion\n",
    "    TestInfo2 = TestInfo2.loc['B1':LastQuestion,:]\n",
    "    TestInfo2.rename(index=str, columns={\"(Secondary) OPTIONAL: Additional Standard\" : \"(Primary) Standard\"}, inplace = True)\n",
    "    \n",
    "    #TestInfoALL = pd.concat([TestInfo1, TestInfo2], keys = None, axis = 0)\n",
    "    TestInfoALL = TestInfo1.append(TestInfo2, ignore_index=True)\n",
    "    TestInfoALL.rename (columns={'Possible Points\\nmust be a whole number (>= 1) if OER': 'Possible Points'}, inplace=True)\n",
    "    \n",
    "    return TestInfoALL\n",
    "\n",
    "#########\n",
    "## Create NEW Standards List based off clean test info sheet\n",
    "\n",
    "def constructStandards(TestInfo):\n",
    "    StandardsList = pd.DataFrame()\n",
    "    AllStandards = TestInfo.loc[:,\"(Primary) Standard\"]\n",
    "    UniqueStandards = AllStandards.unique()\n",
    "    StandardsList = pd.DataFrame(data = UniqueStandards, columns = ['Standard Code']) \n",
    "    #StandardsList.rename(columns={\"0\":\"Standards Code\"}, inplace=True)\n",
    "    StandardsList = StandardsList.sort_values(by=['Standard Code'])\n",
    "    StandardsList = StandardsList.reset_index(drop=True)\n",
    "    return StandardsList\n",
    "\n",
    "#####\n",
    "\n",
    "def cleanResponses2(ResponsesFileName,TestInfo):\n",
    "    Responses = pd.DataFrame()\n",
    "    print (TestInfo.index)\n",
    "    Responses = pd.read_excel(ResponsesFileName)\n",
    "    Questions = Responses.columns.values[9:]\n",
    "    StudentID = Responses.loc[:,['Local Student Id']]\n",
    "    StudentResponses = Responses.loc[:,Questions]\n",
    "    StudentResponses2 = StudentResponses\n",
    "    StudentResponses2.columns = 'B' + StudentResponses.columns\n",
    "    \n",
    "    Responses = pd.concat([StudentID, StudentResponses, StudentResponses2], axis = 1)\n",
    "    Responses.index = Responses.loc[:,'Local Student Id']\n",
    "    Responses = Responses.drop(['Local Student Id'], axis = 1)\n",
    "    Responses.columns = TestInfo.index\n",
    "    Responses = Responses.sort_index()\n",
    "    return Responses\n",
    "    \n",
    "    \n",
    "    #StudentResponses2.columns = 'B' + StudentResponses.columns\n",
    "    \n",
    "## Define function to create binary matrix (points earned)\n",
    "# Only creates 1/0 matrix for MC questions\n",
    "\n",
    "def createBinary(Responses, TestInfos):\n",
    "    BinaryMatrix = Responses.copy()\n",
    "    for question in TestInfos.index.values:\n",
    "        if TestInfos.loc[question,'MC, OER (Question Group)'] == 'MC':\n",
    "            for student in Responses.index.values:\n",
    "                if TestInfos.loc[question,'Correct Answer'] == Responses.loc[student,question]:\n",
    "                    BinaryMatrix.loc[student,question] = TestInfos.loc[question,'Possible Points']\n",
    "                else:\n",
    "                    BinaryMatrix.loc[student,question] = 0\n",
    "        else:\n",
    "            continue\n",
    "    return BinaryMatrix\n",
    "\n",
    "\n",
    "## Define function to calculate points per standard for a given test\n",
    "\n",
    "def calcPPS(StandardsList,TestInfos):\n",
    "    PPS = pd.DataFrame()\n",
    "    StandardIDs = StandardsList.loc[:,'Standard Code']\n",
    "    PPS = pd.DataFrame(index = StandardIDs, columns = ['Points'])\n",
    "    for standard in StandardIDs:\n",
    "        PPS.loc[standard,'Points'] = 0\n",
    "        for question in TestInfos.index.values:\n",
    "            if TestInfos.loc[question,'(Primary) Standard'] == standard:\n",
    "                PPS.loc[standard,'Points'] = PPS.loc[standard,'Points'] + TestInfos.loc[question,'Possible Points']\n",
    "            else:\n",
    "                continue\n",
    "    return PPS\n",
    "\n",
    "##\n",
    "## Define function to calculate standards matrix per student\n",
    "\n",
    "def createStandardsMatrix(BinaryMatrix, TestInfos, PPS):\n",
    "    StandardsbyStudent = pd.DataFrame()\n",
    "    StandardIDs = PPS.index.values\n",
    "    StandardsbyStudent = pd.DataFrame(index = BinaryMatrix.index.values, columns = StandardIDs, data = None)\n",
    "    \n",
    "    for standard in StandardsbyStudent.columns:\n",
    "        AlignedQuestions = list()\n",
    "        for question in TestInfos.index.values:\n",
    "            if TestInfos.loc[question,'(Primary) Standard'] == standard:\n",
    "                AlignedQuestions.append(question)\n",
    "            else:\n",
    "                continue\n",
    "        for student in StandardsbyStudent.index:\n",
    "            if PPS.loc[standard,'Points'] == '0':\n",
    "                StandardsbyStudent.loc[student,standard] = 0\n",
    "            else:\n",
    "                PointsEarned = BinaryMatrix.loc[student,AlignedQuestions].sum()\n",
    "                StandardsbyStudent.loc[student,standard] = (PointsEarned)\n",
    "                \n",
    "    return StandardsbyStudent\n",
    "\n",
    "###\n",
    "\n",
    "## Calculate overall mastery for each student for each standard\n",
    "\n",
    "def CalculateTestMastery(StandardsMatrix, PPS):\n",
    "    MasteryMatrix = StandardsMatrix.copy()\n",
    "    for student in MasteryMatrix.index:\n",
    "        for standard in PPS.index:\n",
    "            if PPS.loc[standard,'Points'] == 0:\n",
    "                MasteryMatrix.loc[student,standard] = np.NaN\n",
    "            else:\n",
    "                MasteryMatrix.loc[student,standard] = StandardsMatrix.loc[student,standard]/PPS.loc[standard,'Points']\n",
    "    return (MasteryMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=138, step=1)\n",
      "RangeIndex(start=0, stop=20, step=1)\n"
     ]
    }
   ],
   "source": [
    "## Import/Clean Info Pages, Import/Clean Responses, Create Binary Matrices\n",
    "\n",
    "ImportTeacherConfig()\n",
    "Roster = ImportRoster()\n",
    "\n",
    "DatesAssessed = GetDatesAssessed()\n",
    "TestInfoNames = GetTestInfoPaths() \n",
    "ResponsesNames = GetResponsesPaths()\n",
    "\n",
    "IndexDataFrame = pd.DataFrame(index= DatesAssessed, data={'TestInfo': TestInfoNames, 'Responses': ResponsesNames})\n",
    "\n",
    "TestInfos = pd.DataFrame()\n",
    "Responses = pd.DataFrame()\n",
    "Binaries = pd.DataFrame()\n",
    "PPSs = pd.DataFrame()\n",
    "StandardsMatrices = pd.DataFrame()\n",
    "\n",
    "#Blank dictionary for collecting all test's data frames\n",
    "TestInfo_collection = {} \n",
    "\n",
    "for Dates in IndexDataFrame.index:\n",
    "    filepath = IndexDataFrame.loc[Dates, 'TestInfo']\n",
    "    TestInfo_collection[Dates]= cleanTestInfo2(filepath)\n",
    "\n",
    "#print (dataframe_collection)\n",
    "\n",
    "SuperTestForStandards = pd.DataFrame()\n",
    "for Dates in TestInfo_collection:\n",
    "    SuperTestForStandards = pd.concat([SuperTestForStandards, TestInfo_collection[Dates]], axis=0)\n",
    "\n",
    "StandardsList = constructStandards(SuperTestForStandards)\n",
    "StandardsList.dropna(inplace=True)\n",
    "\n",
    "Responses = pd.DataFrame()\n",
    "Responses.drop(Responses.index, inplace = True)\n",
    "\n",
    "Responses_collection = {}\n",
    "for Dates in IndexDataFrame.index:\n",
    "    #filepath = IndexDataFrame.loc[Dates, 'TestInfo']\n",
    "    filepath2 = IndexDataFrame.loc[Dates, 'Responses']\n",
    "    \n",
    "    Responses_collection[Dates]= cleanResponses2(filepath2, TestInfo_collection[Dates])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Binaries_collection = {} \n",
    "PPSs_collection = {}\n",
    "StandardsMatrix_collection = {}\n",
    "\n",
    "for Dates in IndexDataFrame.index:\n",
    "    Binaries_collection[Dates] = createBinary(Responses_collection[Dates],TestInfo_collection[Dates])\n",
    "    PPSs_collection[Dates] = calcPPS(StandardsList, TestInfo_collection[Dates])\n",
    "    StandardsMatrix_collection[Dates] = createStandardsMatrix(Binaries_collection[Dates],TestInfo_collection[Dates],PPSs_collection[Dates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TestMastery_collection = {}\n",
    "#print (StandardsMatrix_collection)\n",
    "\n",
    "for Dates in IndexDataFrame.index:\n",
    "   TestMastery_collection[Dates] = CalculateTestMastery(StandardsMatrix_collection[Dates], PPSs_collection[Dates])\n",
    "\n",
    "TestOverallMastery_collection = {}\n",
    "\n",
    "for Dates in IndexDataFrame.index:\n",
    "    TestOverallMastery_collection[Dates] =  TestMastery_collection[Dates].mean(axis = 0, skipna = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Matrices\n",
    "OverallBinaries = pd.DataFrame()\n",
    "OverallPPS = pd.DataFrame()\n",
    "OverallStandardsMastery = pd.DataFrame()\n",
    "\n",
    "# Final Matrix\n",
    "OverallStudentMastery = pd.DataFrame()\n",
    "\n",
    "for Dates in IndexDataFrame.index:\n",
    "    OverallPPS = OverallPPS.add(PPSs_collection[Dates], fill_value = 0)\n",
    "    OverallStandardsMastery = OverallStandardsMastery.add(StandardsMatrix_collection[Dates], fill_value = 0)\n",
    "\n",
    "OverallPPS\n",
    "#OverallStandardsMastery\n",
    "\n",
    "OverallStudentMastery = OverallStandardsMastery.divide(OverallPPS.loc[:,'Points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard Code</th>\n",
       "      <td>UHAI.HS.Calc.01.Asymptotes</td>\n",
       "      <td>UHAI.HS.Calc.01.Continuity</td>\n",
       "      <td>UHAI.HS.Calc.01.IVT</td>\n",
       "      <td>UHAI.HS.Calc.01.LimGraph</td>\n",
       "      <td>UHAI.HS.Calc.01.LimInf</td>\n",
       "      <td>UHAI.HS.Calc.02.DerivApprox</td>\n",
       "      <td>UHAI.HS.Calc.02.DerivInterpret</td>\n",
       "      <td>UHAI.HS.Calc.02.DerivLimitDef</td>\n",
       "      <td>UHAI.HS.Calc.02.DerivMatching</td>\n",
       "      <td>UHAI.HS.Calc.02.Differentiability</td>\n",
       "      <td>...</td>\n",
       "      <td>UHAI.HS.Calc.06.RiemannSums</td>\n",
       "      <td>UHAI.HS.Calc.07.AvgValueAROC</td>\n",
       "      <td>UHAI.HS.Calc.07.IntByParts</td>\n",
       "      <td>UHAI.HS.Calc.07.IntLongDivision</td>\n",
       "      <td>UHAI.HS.Calc.07.IntSimplify</td>\n",
       "      <td>UHAI.HS.Calc.07.IntSub</td>\n",
       "      <td>UHAI.HS.Calc.08.Euler</td>\n",
       "      <td>UHAI.HS.Calc.08.Exponential</td>\n",
       "      <td>UHAI.HS.Calc.08.IVP</td>\n",
       "      <td>UHAI.HS.Calc.08.SlopeField</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                           1   \\\n",
       "Standard Code  UHAI.HS.Calc.01.Asymptotes  UHAI.HS.Calc.01.Continuity   \n",
       "\n",
       "                                2                         3   \\\n",
       "Standard Code  UHAI.HS.Calc.01.IVT  UHAI.HS.Calc.01.LimGraph   \n",
       "\n",
       "                                   4                            5   \\\n",
       "Standard Code  UHAI.HS.Calc.01.LimInf  UHAI.HS.Calc.02.DerivApprox   \n",
       "\n",
       "                                           6                              7   \\\n",
       "Standard Code  UHAI.HS.Calc.02.DerivInterpret  UHAI.HS.Calc.02.DerivLimitDef   \n",
       "\n",
       "                                          8   \\\n",
       "Standard Code  UHAI.HS.Calc.02.DerivMatching   \n",
       "\n",
       "                                              9              ...              \\\n",
       "Standard Code  UHAI.HS.Calc.02.Differentiability             ...               \n",
       "\n",
       "                                        39                            40  \\\n",
       "Standard Code  UHAI.HS.Calc.06.RiemannSums  UHAI.HS.Calc.07.AvgValueAROC   \n",
       "\n",
       "                                       41                               42  \\\n",
       "Standard Code  UHAI.HS.Calc.07.IntByParts  UHAI.HS.Calc.07.IntLongDivision   \n",
       "\n",
       "                                        43                      44  \\\n",
       "Standard Code  UHAI.HS.Calc.07.IntSimplify  UHAI.HS.Calc.07.IntSub   \n",
       "\n",
       "                                  45                           46  \\\n",
       "Standard Code  UHAI.HS.Calc.08.Euler  UHAI.HS.Calc.08.Exponential   \n",
       "\n",
       "                                47                          48  \n",
       "Standard Code  UHAI.HS.Calc.08.IVP  UHAI.HS.Calc.08.SlopeField  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create assessment x standard martix to be write-ready\n",
    "\n",
    "MasterByTest = pd.DataFrame(TestOverallMastery_collection)\n",
    "\n",
    "## Removed Standards List from the Process\n",
    "\n",
    "#StandardsList_processed = StandardsList_processed [['Unit', 'Last Date Assessed', 'Priority', 'Standard Code']]\n",
    "MasterByTest = MasterByTest.fillna(value='')\n",
    "MasterByTest = MasterByTest.T\n",
    "MasterByTest.head()\n",
    "\n",
    "StandardsList_processed = StandardsList.copy()\n",
    "#StandardsList_processed = StandardsList_processed [['Unit', 'Last Date Assessed', 'Priority', 'Standard Code']]\n",
    "StandardsList_processed = StandardsList_processed.fillna(value='')\n",
    "StandardsList_processed = StandardsList_processed.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Roster df in order\n",
    "Data_processed = pd.DataFrame()\n",
    "Roster_processed = Roster.copy()\n",
    "#cols = Roster2.columns.tolist() \n",
    "#cols = [cols[:0]]+[cols[2]]+[cols[1]]\n",
    "#Roster2 = Roster2[cols]\n",
    "#Roster2 = Roster2.ix[:, cols]\n",
    "# \tLast, First \tTeacher \tSection\n",
    "\n",
    "## Roster_processed.head()\n",
    "Data_processed = pd.merge(Roster_processed, OverallStudentMastery, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "Data_processed\n",
    "\n",
    "Data_left = Data_processed.iloc[:, 0:4]\n",
    "x = Data_processed.shape[1]\n",
    "Data_right = Data_processed.iloc[:, 4:x]\n",
    "\n",
    "DatesofTests = pd.DataFrame(columns=['Dates'], data=IndexDataFrame.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet 'AP Calc BC - Coapman' id:oz8h307>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time to upload\n",
    "from df2gspread import df2gspread as d2g\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials2 = ServiceAccountCredentials.from_json_keyfile_name('creds.json', scope)\n",
    "\n",
    "gc = gspread.authorize(credentials2)\n",
    "\n",
    "# Get the info from ini file that was loaded way back up in the code\n",
    "wks = str(ImportTeacherConfig()[0])\n",
    "spreadsheet = str(ImportTeacherConfig()[1])\n",
    "\n",
    "#Upload  Data\n",
    "d2g.upload(Data_left, gfile=spreadsheet, wks_name=wks, start_cell='A37', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)\n",
    "d2g.upload(Data_right, gfile=spreadsheet, wks_name=wks, start_cell='F37', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)\n",
    "\n",
    "\n",
    "#Upload the Standards themselves to TWO locations.\n",
    "d2g.upload(StandardsList_processed, gfile=spreadsheet, wks_name=wks, start_cell='D16', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)\n",
    "d2g.upload(MasterByTest, gfile=spreadsheet, wks_name=wks, start_cell='D18', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)\n",
    "d2g.upload(StandardsList_processed, gfile=spreadsheet, wks_name=wks, start_cell='F36', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)\n",
    "d2g.upload(DatesofTests, gfile=spreadsheet, wks_name=wks, start_cell='A18', credentials=credentials2, clean=False, df_size=False, col_names=False, row_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
